{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stochastic_Processes_&_Optimization_in_Machine_Learning_(Lab_8_DNS_Water_Torture).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLUCLr2dsyWQ"
      },
      "source": [
        "<b><h1>DNS Water Torture σε Recursive DNS Servers</h1></b>\n",
        "\n",
        "<p align=\"justify\">Στην άσκηση αυτή, θα αναπτύξετε ένα μηχανισμό αντιμετώπισης επιθέσεων <i>DNS Water Torture</i> σε <i>Recursive DNS Servers</i> (δίνεται <a href=\"https://github.com/nkostopoulos/StochasticsLabPublic/blob/master/lab8/Lab8_theory.pdf\">υποστηρικτικό υλικό</a> για την άσκηση). Ουσιαστικά, το πρόβλημα αυτό είναι ένα πρόβλημα text classification που έγγειται στο διαχωρισμό ονομάτων DNS που είναι <i>έγκυρα (valid)</i> και <i>άκυρα (invalid)</i>. </p>\n",
        "\n",
        "<p align=\"justify\">Με τη βοήθεια του αλγορίθμου Naive Bayes Classifier, θα διαχωρίσετε τα prefixes των <i>ονομάτων DNS</i> σε <i>έγκυρα</i> και <i>άκυρα</i>. Στην άσκηση αυτή, ως <i>prefix</i> ορίζουμε το <i>πρώτο label</i> ενός <i>ονόματος DNS</i>. Για παράδειγμα, το prefix του ονόματος <a href=\"https://www.ntua.gr/el/\">www.ntua.gr</a> είναι το <i>www</i>, ενώ το prefix του ονόματος <a href=\"dolly.netmode.ece.ntua.gr\">dolly.netmode.ece.ntua.gr</a> είναι το <i>dolly</i>.</p>\n",
        "\n",
        "<p align=\"justify\">Ο αλγόριθμος θα εκπαιδευτεί με <u>έγκυρα ονόματα</u> (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab8/valid_training.txt\">valid_training.txt</a>) και άκυρα ονόματα (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab8/invalid_training.txt\">invalid_training</a>.txt). Η δοκιμή του θα γίνει στο <u>test set</u>, που περιλαμβάνει, επίσης, έγκυρα (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab8/valid_test.txt\">valid_test.txt</a>) και άκυρα (αρχείο <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab8/invalid_test.txt\">invalid_test.txt</a>) ονόμάτα.</p>\n",
        "\n",
        "<p align=\"justify\">Να απαντήσετε στις ακόλουθες ερωτήσεις:</p>\n",
        "<ul>\n",
        "<li>Ποια είναι η παραδοχή του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>; Ποια είναι τα πλεονεκτήματα του αλγορίθμου;</li>\n",
        "<li>Να περιγράψετε σύντομα τη λειτουργία του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>.</li>\n",
        "<li>Μελετήστε τα prefixes που περιλαμβάνονται στα αρχεία <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab8/valid_training.txt\">valid_training.txt</a> και <a href=\"https://raw.githubusercontent.com/nkostopoulos/StochasticsLabPublic/master/lab8/invalid_training.txt\">invalid_training.txt</a>. Σχολιάστε μερικές από τις βασικές διαφορές ανάμεσα στα prefixes των δύο αρχείων που θα μπορούσαν να φανούν χρήσιμες για το διαχωρισμό των έγκυρων και των άκυρων ονομάτων.</li>\n",
        "<li>Ποια είναι τα 7 features που έχουν επιλεχθεί στον κώδικα της άσκησης;</li>\n",
        "<li>Να εκτελέσετε τον κώδικα της άσκησης. Καταγράψετε και σχολιάστε την ακρίβεια του αλγορίθμου πάνω στο <i>test set</i> για τα valid και τα invalid names ξεχωριστά. Ποιο είναι το μέγεθος του <i>training set</i>; Πόση ώρα διήρκησε η εκπαίδευση του αλγορίθμου;</li>\n",
        "<li>Αφού εκτελέσετε τον κώδικα, θα παρατηρήσετε πως έχουν παραχθεί δύο αρχεία: <i>problematic_valid.txt</i> και <i>problematic_invalid.txt</i>. Μελετώντας τον κώδικα, γιατί πιστεύετε ότι τα prefixes που περιλαμβάνονται σε αυτά τα αρχεία δημιουργούν πρόβλημα στην περίπτωσή μας; Θυμηθείτε τα μειονεκτήματα του αλγορίθμου <b><i>Naive Bayes Classifier</i></b>. Τι θα μπορούσατε να κάνετε για να λύσετε το πρόβλημα αυτό (<a href=\"https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf\">https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf</a>);</li>\n",
        "<li>Μελετώντας τη συνάρτηση <i>find_prob()</i>, θα δείτε πως λείπουν οι πιθανότητες <i>prior</i> από τους υπολογισμούς. Τι παραδοχή έχουμε κάνει για τις <i>prior</i> πιθανότητες και κατά συνέπεια για τις δύο κατηγορίες ταξινόμησης (<i>valid</i>, <i>invalid</i>) στην άσκησή μας; Πώς αλλιώς θα μπορούσατε να τις επιλέξετε;</li>\n",
        "<li>Μπορείτε να προτείνετε κάποιο επιπρόσθετο <i>feature</i> για τον αλγόριθμο; (δε χρειάζεται να το υλοποιήσετε)</li>\n",
        "</ul>\n",
        "\n",
        "<p align=\"justify\"><b>Πηγές Δεδομένων</b></p>\n",
        "<ul>\n",
        "<li>Valid ονόματα: <a href=\"https://www.kaggle.com/cheedcheed/top1m\">https://www.kaggle.com/cheedcheed/top1m</a> (πολλά από τα κορυφαία σε επισκεψιμότητα site)</li>\n",
        "<li>Invalid ονόματα: Παράχθηκαν με το πρόγραμμα <a href=\"https://github.com/nkostopoulos/StochasticsLabPublic/blob/master/lab8/generator.py\">generator.py</a> που θα βρείτε μαζί με τα υπόλοιπα αρχεία της άσκησης.</li>\n",
        "</ul>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fl3dehbveVgA"
      },
      "source": [
        "### Απαντήσεις\n",
        "\n",
        "1. Η παραδοχή που κάνει ο Naive Bayes Classifier είναι ότι τα features, δηλαδή τα inputs είναι όλα ανεξάρτητα μεταξύ τους καθώς επίσης συμβάλλουν το ίδιο στο μοντέλο ταξινόμησης. Τα πλεονεκτήματα του αλγορίθμου είναι ότι είναι αρκετά εύκολος να εφαρμοστεί, διαθέτει γρήγορο inference και μπορεί να χειριστεί datasets με μεγάλο αριθμό features.\n",
        "\n",
        "2. Ο Naive Bayes Classifier προσπαθεί να υπολογίσει την πιθανότητα ένα σύνολο από attributes να ανήκουν στην c class. Δηλαδή P(c|x)  (c, target) (x, attributes). Κάνοντας χρήση του θεωρήματος του Bayes μετατρέπει αυτή τη πιθανότητα στο εξής : \n",
        "\n",
        "$\\frac{P(x|c)*P(c)}{P(x)}$\n",
        "\n",
        "Από τα δεδομένα οι παραπάνω πιθανότητες είναι υπολογίσιμες και στο τέλος υπολογίζει την πιθανότητα για όλες τις κλάσεις και η κλάση με την μεγαλύτερη πιθανότητα είναι το αποτέλεσμα του αλγορίθμου.\n",
        "\n",
        "3. Μια από τις διαφορές που εντοπίζουμε είναι ότι το μήκος των λέξεων στο invalid είναι αρκετά μεγαλύτερο. Επίσης η χρήση αριθμών στο invalid είναι αρκετά πιο συχνή. Τέλος η αναγνώριση πραγματικών λέξεων μπορεί να φανεί χρήσιμη καθώς το invalid έχει τυχαία σύμβολα στη σειρά.\n",
        "\n",
        "4. Έχουν επιλεχθεί: Συνολικό Μήκος, Αριθμό ψηφίων, Μέγιστη αριθμητική ακολουθία, Συνολικά σύμφωνα, Μέγιστη ακολουθία από συμφωνα, Συνολικά φωνήεντα, Μέγιστη ακολουθία από φωνήεντα.\n",
        "\n",
        "5. Υπολογίζουμε 1-Misclassified_Ratio/100. Για το valid είχαμε 0.98082705259 ,  δηλαδή το 98% των περιπτώσεων που εξεταστεί ένα valid ονομα θα ταξινομηθεί ως valid. Αντίστοιχα για το invalid έχουμε 0.98734417832. Αρκετά υψηλά νούμερα και για τις 2 κατηγορίες.To training set έχει 70000 valid names και 70000 invalid names άρα συνολικά 140000 prefixes. O χρόνος εκπαίδευσης του αλγορίθμου είναι περίπου 20 seconds.\n",
        "\n",
        "6. Παρατηρήσαμε στο problematic invalid ότι δεν έχουμε πολλά ψηφία στα ονόματα τους καθώς επίσης υπάρχουν μικρές ακολουθίες ακολουθίες από ψηφία. Αντίστοιχα στο problematic valid έντονο χαρακτηριστικό είναι το μήκος του ονόματος που είτε θα είναι πολύ μικρό είτε πολύ μεγάλο, όχι όμως το μήκος που έχει συνηθίσει απο το training set και παρατηρούμε αρκετά ψηφία σε ορισμένα ονόματα. Πάντοτε τα χαρακτηριστικά αυτά πρέπει να αντιστοιχούν στις συχνότητες εμφάνισης στο training set. Ένα από τα προβλήματα του Naive Bayes είναι ότι πρέπει να βρεθούν όλα τα χαρακτηριστικά τα οποία έχουν εντοπιστεί στο training σετ, διαφορετικά η posterior πιθανότητα γίνεται 0. Επομένως αν όλα τα χαρακτηριστικά έκτος από 1 έχουν εμφανιστεί πάρα πολλές φορές στο valid set , ενώ έχουν εμφανιστεί όλα ελάχιστες φορές στο invalid σετ , το μοντέλο θα αποφανθεί invalid prefix πιθανότατα λανθασμένα. Για να διορθωθεί αυτό μπορούμε να εισάγουμε έναν παράγοντα alpha στις posterior πιθανότητες, μη μηδενικό , ο οποίος θα διορθώνει τις μηδενικές πιθανότητες. Η τεχνική αυτή ονομάζεται smoothing.\n",
        "\n",
        "7. Δεν υπολογίζονται οι prior πιθανότητες ούτε της κάθε κλάσης ούτε του κάθε feature. Δεν χρειάζεται να υπολογιστεί κάθε feature καθώς στο τέλος ο αλγόριθμος όταν συγκρίνει τις δυο πιθανότητες, οι παρανομαστές θα είναι ίσοι.\n",
        "Δεν υπολογίζεται ούτε η prior πιθανότητα κάθε κλάσης ξεχωριστά καθώς υπάρχει μέσα στον υπολογισμό. Οι δεσμευμένες πιθανότητες έχουν στον παρονομαστή το πλήθος της κλάσης που μας ενδιαφέρει και επομένως θα γινόταν απλοποίηση. Αν θέλαμε να τις συμπεριλάβουμε τότε θα μπορούσαμε να μετρήσουμε το μέγεθος του valid και invalid και να διαιρέσουμε με το μέγεθος του συνολικού dataset. Σε αυτή την περίπτωση όμως αντί να διαιρούμε τις conditional probs με το μήκος του συνολικού dataset θα διαιρέσουμε το αντίστοιχο μήκος του σετ στο οποίο βρίσκεται (valid, invalid).\n",
        "\n",
        "8. Σαν έξτρα feature θα μπορούσε να προστεθεί αν υπάρχουν στο prefix , υπαρκτές λέξεις του αγγλικού λεξιλογίου, για παράδειγμα μέσω μιας nlp βιβλιοθήκης (PyEnchant).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c0OM-5nc8JI",
        "outputId": "6a1493d8-b7fd-4589-8250-da50732167b2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwzSpcfKrXpi"
      },
      "source": [
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_plJQ1Z2i5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a151f3dd-7835-4507-8ad0-c9534dff3c25"
      },
      "source": [
        "problematic1 = open(\"problematic_valid.txt\", \"w\")\n",
        "problematic2 = open(\"problematic_invalid.txt\", \"w\")\n",
        "\n",
        "def load_file(file_name):\n",
        "    fd = open(file_name, \"r\")\n",
        "    my_set = set()\n",
        "    for prefix in fd:\n",
        "        prefix = prefix.rstrip()\n",
        "        my_set.add(prefix)\n",
        "    return my_set\n",
        "\n",
        "def calculate_probabilities(dataset):\n",
        "    stats = dict()\n",
        "    for index in range(0, 7):\n",
        "        stats[index] = dict()\n",
        "    for prefix in dataset:\n",
        "        features = handle_name(prefix)\n",
        "        for index in range(0, 7):\n",
        "            try:\n",
        "                stats[index][features[index]] += 1\n",
        "            except:\n",
        "                stats[index][features[index]] = 1\n",
        "\n",
        "    dataset_size = len(dataset)    \n",
        "    for index in range(0, 7):\n",
        "        for key in stats[index]:\n",
        "            stats[index][key] /= dataset_size\n",
        "    return stats\n",
        "\n",
        "def handle_name(prefix):\n",
        "    total_length = len(prefix)\n",
        "    total_digits, max_numeric_sequence = numeric(prefix)\n",
        "    total_consonants, max_consonants_sequence = consonants(prefix)\n",
        "    total_vowels, max_vowels_sequence = vowels(prefix)\n",
        "    return total_length, total_digits, max_numeric_sequence, total_consonants, max_consonants_sequence, total_vowels, max_vowels_sequence\n",
        "\n",
        "def vowels(prefix):\n",
        "    total_vowels = 0\n",
        "    vowels_sequence = list()\n",
        "    current_sequence = 0\n",
        "    for char in prefix:\n",
        "        if char == 'a' or char == 'e' or char == 'i' or char == 'o' or char == 'u':\n",
        "            total_vowels += 1\n",
        "            current_sequence += 1\n",
        "        else:\n",
        "            vowels_sequence.append(current_sequence)\n",
        "            current_sequence = 0\n",
        "    vowels_sequence.append(current_sequence)\n",
        "    max_vowels_sequence = max(vowels_sequence)\n",
        "    return total_vowels, max_vowels_sequence\n",
        "\n",
        "def consonants(prefix):\n",
        "    total_consonants = 0\n",
        "    consonants_sequence = list()\n",
        "    current_sequence = 0\n",
        "    for char in prefix:\n",
        "        if char != 'a' and char != 'e' and char != 'i' and char != 'o' and char != 'u' and char != '-' and char.isdigit() == False:\n",
        "            total_consonants += 1\n",
        "            current_sequence += 1\n",
        "        else:\n",
        "            consonants_sequence.append(current_sequence)\n",
        "            current_sequence = 0\n",
        "    consonants_sequence.append(current_sequence)\n",
        "    max_consonants_sequence = max(consonants_sequence)\n",
        "    return total_consonants, max_consonants_sequence\n",
        "\n",
        "def numeric(prefix):\n",
        "    total_digits = 0\n",
        "    numeric_sequence = list()\n",
        "    current_sequence = 0\n",
        "    for char in prefix:\n",
        "        if char.isdigit() == True:\n",
        "            total_digits += 1\n",
        "            current_sequence += 1\n",
        "        else:\n",
        "            numeric_sequence.append(current_sequence)\n",
        "            current_sequence = 0\n",
        "    numeric_sequence.append(current_sequence)\n",
        "    max_numeric_sequence = max(numeric_sequence)\n",
        "    return total_digits, max_numeric_sequence\n",
        "            \n",
        "def find_prob(prefix, stats, fd):\n",
        "    tl, td, mns, tc, mcs, tv, mvs = handle_name(prefix)\n",
        "    try:\n",
        "        prob = stats[0][tl] * stats[1][td] * stats[2][mns] * stats[3][tc] * stats[4][mcs] * stats[5][tv] * stats[6][mvs]\n",
        "    except:\n",
        "        prob = 0\n",
        "        fd.write(prefix + \"\\n\")\n",
        "    return prob\n",
        "\n",
        "def apply_on_test_set(test_set, category, valid_stats, invalid_stats, fd):\n",
        "    misclassifications = 0\n",
        "    names_processed = 0\n",
        "    for prefix in test_set:\n",
        "        valid_prob = find_prob(prefix, valid_stats, fd)\n",
        "        invalid_prob = find_prob(prefix, invalid_stats, fd)\n",
        "        if valid_prob != 0 and invalid_prob != 0:\n",
        "            names_processed += 1\n",
        "            if category == \"valid\" and valid_prob < invalid_prob:\n",
        "                misclassifications += 1\n",
        "            elif category == \"invalid\" and valid_prob > invalid_prob:\n",
        "                misclassifications += 1\n",
        "    return misclassifications, names_processed\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load valid names training set\n",
        "    valid_names_training = load_file(\"/content/drive/MyDrive/stoch/valid_training.txt\")\n",
        "    # Load valid names test set\n",
        "    valid_names_test = load_file(\"/content/drive/MyDrive/stoch/valid_test.txt\")\n",
        "    # Load invalid names training set\n",
        "    invalid_names_training = load_file(\"/content/drive/MyDrive/stoch/invalid_training.txt\")\n",
        "    # Load invalid names test set\n",
        "    invalid_names_test = load_file(\"/content/drive/MyDrive/stoch/invalid_test.txt\") \n",
        "\n",
        "    #print(len(valid_names_training))\n",
        "    #print(len(invalid_names_training))\n",
        "    start_time = time.time()\n",
        "\n",
        "    valid_stats = calculate_probabilities(valid_names_training)\n",
        "    invalid_stats = calculate_probabilities(invalid_names_training)\n",
        "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "    valid_misclassifications, valid_names_processed = apply_on_test_set(valid_names_test, \"valid\", valid_stats, invalid_stats, problematic1)\n",
        "    invalid_misclassifications, invalid_names_processed = apply_on_test_set(invalid_names_test, \"invalid\", valid_stats, invalid_stats, problematic2)\n",
        "\n",
        "    print(\"Valid names misclassified as invalid - Ratio: \", (valid_misclassifications / valid_names_processed) * 100)\n",
        "    print(\"Invalid names misclassified as valid - Ratio: \", (invalid_misclassifications / invalid_names_processed) * 100)\n",
        "\n",
        "    \n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- 20.006479263305664 seconds ---\n",
            "Valid names misclassified as invalid - Ratio:  1.9172947402180884\n",
            "Invalid names misclassified as valid - Ratio:  1.2655821677971868\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}