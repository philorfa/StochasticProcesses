{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stochastic_Processes_&_Optimization_in_Machine_Learning_(Lab_3_Exercise_4).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LsZdK1LTB1T"
      },
      "source": [
        "<h1><b>Άσκηση 4</b></h1>\n",
        "<p align=\"justify\">Η μέθοδος Monte Carlo είναι μια υπολογιστική μέθοδος, που βασίζεται στο νόμο των μεγάλων αριθμών. Αν {Χ<sub>n</sub>}<sub>n∈N</sub> είναι μια ακολουθία από ανεξάρτητες, ισόνομες τυχαίες μεταβλητές, με πεπερασμένη μέση τιμή Ε[Χ], τότε:</p>\n",
        "\n",
        "$$\n",
        "P\\left[\n",
        "\\frac{1}{n}\\sum_{k=1}^{n}X_k \\rightarrow E[X]\n",
        "\\right] = 1\n",
        "$$\n",
        "\n",
        "<p align=\"justify\">Προκειμένου να υπολογίσουμε τη μέση τιμή Ε[Χ]  μιας τυχαίας μεταβλητής Χ, μπορούμε λοιπόν να πάρουμε το μέσο όρο ενός μεγάλου αριθμού ανεξάρτητων δειγμάτων αυτής της μεταβλητής. Με παρόμοιο τρόπο, μπορούμε να προσεγγίσουμε υπολογιστικά την πιθανότητα ενός ενδεχομένου από το κλάσμα των πραγματοποιήσεών του σε μια σειρά από <b>m</b> ανεξάρτητες προσομοιώσεις μέχρι το βήμα <b>n</b>, δηλαδή:</p>\n",
        "\n",
        "$$\n",
        "P\\left[\n",
        "\\frac{1}{m} \\sum_{k=1}^{m}H_k \\rightarrow P[X_n | X_0]\n",
        "\\right] = 1\n",
        "$$\n",
        "\n",
        "<p align=\"justify\">όπου η τυχαία μεταβλητή Η_k παίρνει την τιμή 1 εάν το ενδεχόμενο πραγματοποιείται στο τέλος του εκάστοτε πειράματος και 0 στην αντίθετη περίπτωση. Σ’ αυτήν την ιδέα θα βασιστεί η άσκηση αυτή. Σας δίνεται η μαρκοβιανή αλυσίδα στο χώρο καταστάσεων <b>Χ</b>={1,2,3} με πίνακα πιθανοτήτων μετάβασης:</p>\n",
        "\n",
        "$$\n",
        "P = \\begin{pmatrix}\n",
        "0 & 1 & 0\\\\\n",
        "0 & 2/3 & 1/3\\\\\n",
        "1/6 & 5/6 & 0\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "<p align=\"justify\">Χρησιμοποιώντας το πρόγραμμα που δίνεται παρακάτω, θα πραγματοποιήσετε <b>m</b> ανεξάρτητα πειράματα για να εκτιμήσετε την πιθανότητα <b>Για να τρέξετε το πρόγραμμα θα πρέπει να έχετε φορτώσει το αρχείο <i><a href=\"https://github.com/nkostopoulos/StochasticsLabPublic/blob/master/lab3/simple_markov_chain_lib.py\">simple_markov_chain_lib.py</a></i></b>.</p>\n",
        "\n",
        "$$\n",
        "P\\left[\n",
        "X_{40} = 1 | X_0 = 1\n",
        "\\right]\n",
        "$$\n",
        "\n",
        "<p align=\"justify\">δηλαδή την πιθανότητα να βρίσκεται η αλυσίδα στην κατάσταση 1 στο 40ό βήμα της δεδομένου ότι ξεκίνησε από την κατάσταση 1. Για να ελέγξετε την ορθότητα της μεθόδου, το πρόγραμμα περιλαμβάνει και τον ακριβή υπολογισμό της παραπάνω πιθανότητας.</p> \n",
        "<ul>\n",
        "<li>Να μελετήσετε το πρόγραμμα και να περιγράψετε σύντομα τη μέθοδο που ακολουθείται.</li>\n",
        "<li>Να επαναλάβετε τη διαδικασία για τιμές της παραμέτρου m: (α) 1,000, (β) 10,000, (γ) 50,000, (δ) 100,000, (ε) 500,000. Να καταγράψετε και να σχολιάσετε την τιμή της παραπάνω πιθανότητας όπως υπολογίζεται από την προσομοίωση σε σχέση με την ακριβή τιμή της.</li>\n",
        "</ul>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "OWtw7e3UXIec"
      },
      "source": [
        "#@title\n",
        "from bisect import bisect_left\n",
        "from random import random\n",
        "\n",
        "import networkx as nx  # get communication classes\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "\n",
        "class markov_chain:\n",
        "\n",
        "    def __init__(self, markov_table, init_dist=None):\n",
        "        \"\"\"\n",
        "        Constructs a Markov Chain from a transition matrix.\n",
        "        The initial distribution can be provided or setted aftewards.\n",
        "        \"\"\"\n",
        "\n",
        "        # Attributes\n",
        "        self.running_state = None\n",
        "        self.steps = 0\n",
        "        self.visits = {state: 0 for state in markov_table}\n",
        "        size = len(markov_table)\n",
        "\n",
        "        # Set up state transition probs\n",
        "        self._states = {state: self._partial_sums(dist)\n",
        "                        for state, dist in markov_table.items()}\n",
        "        for state, dist in self._states.items():\n",
        "            if not np.isclose(dist[-1][0], 1.0):\n",
        "                msg = \"State {} transitions do not add up to 1.0\".format(state)\n",
        "                raise ValueError(msg)\n",
        "        self._probs_state = np.array([0] * size)\n",
        "\n",
        "        # Adjacency Matrix\n",
        "        data, rows, cols = [], [], []\n",
        "        for row, dist in markov_table.items():\n",
        "            col, pval = zip(*[(s, p) for s, p in dist.items() if p > 0])\n",
        "            rows += [row] * len(col)\n",
        "            cols += col\n",
        "            data += pval\n",
        "        # make sure they are in the right order\n",
        "        enum = {state: i for i, state in enumerate(self._states)}\n",
        "        rows = [enum[r] for r in rows]\n",
        "        cols = [enum[c] for c in cols]\n",
        "        self._adj = csr_matrix((data, (rows, cols)), shape=(size, size))\n",
        "\n",
        "        # Communication Classes\n",
        "        classes = {'Closed': [], 'Open': []}\n",
        "        g = nx.MultiDiGraph(self._adj)\n",
        "        scc = list(nx.strongly_connected_components(g))\n",
        "        g = nx.condensation(g)  # SCCs collapse to single nodes\n",
        "        for n in g:\n",
        "            if g.out_degree(n) == 0:\n",
        "                classes[\"Closed\"].append(scc[n])\n",
        "            else:\n",
        "                classes[\"Open\"].append(scc[n])\n",
        "        self.communication_classes = classes\n",
        "\n",
        "        # Set Initial State\n",
        "        self._init_dist = None\n",
        "        if init_dist is not None:\n",
        "            self.init_dist = init_dist\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"The cardinality of the state-space\"\"\"\n",
        "        return len(self._states)\n",
        "\n",
        "    @property\n",
        "    def probs_matrix(self):\n",
        "        \"\"\"The transition probability matrix\"\"\"\n",
        "        return self._adj.toarray()\n",
        "\n",
        "    @property\n",
        "    def probs_state(self):\n",
        "        \"\"\"\n",
        "        Computes analytically the probability of being in every state at\n",
        "        currentn step. Returns a vector of state probabilities\n",
        "        \"\"\"\n",
        "        init_dist = np.array([self.init_dist.get(state, 0.0)\n",
        "                              for state in self._states])\n",
        "        probs = init_dist @ (self._adj ** self.steps)\n",
        "        return dict(zip(self._states, probs))\n",
        "\n",
        "    @property\n",
        "    def init_dist(self):\n",
        "        \"\"\"The initial distribution of the chain\"\"\"\n",
        "        return self._init_dist\n",
        "\n",
        "    @init_dist.setter\n",
        "    def init_dist(self, dist):\n",
        "        if not np.isclose(sum(dist.values()), 1.0):\n",
        "            msg = \"The transition probabilities of init_dist must add up to 1.0\"\n",
        "            raise ValueError(msg)\n",
        "        self._init_dist = dist\n",
        "        self._state0 = self._partial_sums(dist)\n",
        "        self.running_state = None\n",
        "\n",
        "    @property\n",
        "    def eigenvalues(self):\n",
        "        \"\"\"Returns the eigenvalues of the transition table\"\"\"\n",
        "        return list(np.sort(np.linalg.eigvals(self.probs_matrix)))\n",
        "\n",
        "    def _partial_sums(self, dist):\n",
        "        \"\"\"\n",
        "        Takes as input a row of the probability matrix (dist)\n",
        "        and generates its partial sums.\n",
        "        These are cached as tuples (sum, state) to be sampled.\n",
        "        \"\"\"\n",
        "        states, probs = zip(*[(s, p) for s, p in dist.items() if p > 0])\n",
        "        probs = np.cumsum(probs)\n",
        "        return list(zip(probs, states))\n",
        "\n",
        "    def _next_state(self, state):\n",
        "        \"\"\"Selects a new state based on the transition probabilities\"\"\"\n",
        "        return state[bisect_left(state, (random(), ))][1]\n",
        "\n",
        "    def start(self):\n",
        "        \"\"\"First step of the chain choosen from the initial distribution\"\"\"\n",
        "\n",
        "        # Initiate walk\n",
        "        self.steps = 0\n",
        "        for state in self._states:\n",
        "            self.visits[state] = 0\n",
        "\n",
        "        # Initialize the state distribution - to be updated as we walk\n",
        "        self.running_state = self._next_state(self._state0)\n",
        "        self.visits[self.running_state] = 1\n",
        "\n",
        "    def move(self):\n",
        "        \"\"\"Moves to the next state and updates all relevant fields\"\"\"\n",
        "        transition_probs = self._states[self.running_state]\n",
        "        self.running_state = self._next_state(transition_probs)\n",
        "        self.steps += 1\n",
        "        self.visits[self.running_state] += 1\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkMG5r8WX1np",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e09da28-abb9-4a06-b4ae-270251d3ce1b"
      },
      "source": [
        "from __future__ import division\n",
        "#from simple_markov_chain_lib import markov_chain\n",
        "import statistics as stat\n",
        "from numpy import matmul\n",
        "import numpy as np\n",
        "\n",
        "def defineMarkovTable(): \n",
        "\tp = 1/6\n",
        "\tmarkov_table = {\n",
        "\t\t1: {2: 1.},\n",
        "\t\t2: {2: 2/3, 3: 1/3},\n",
        "\t\t3: {1: p, 2: 1-p}\n",
        "\t}\n",
        "\n",
        "\treturn markov_table\n",
        "\n",
        "def defineNumpyTable():\n",
        "\tPn = np.array([[0,1,0],\n",
        "\t\t       [0,2/3,1/3],\n",
        "\t\t       [1/6, 5/6, 0]])\n",
        "\tP0 = np.array([[1,0,0]])\n",
        "\t\n",
        "\treturn Pn,P0\n",
        "\n",
        "def multiplyNumpyTables(Pn,P0):\n",
        "\tfor index in range(40):\n",
        "\t\tPn = np.matmul(Pn,Pn)\n",
        "\tPn = np.matmul(P0,Pn)\n",
        "\treturn Pn\n",
        "\n",
        "def defineInitDistribution():\n",
        "\tinit_dist = {1: 1.}\n",
        "\t\n",
        "\treturn init_dist\n",
        "\n",
        "def calculateProbabilities(markov_table, init_dist):\n",
        "\tmc = markov_chain(markov_table, init_dist)\n",
        "\texperiments = 500000\n",
        "\tsteps = 40\n",
        "\tvisits = 0\n",
        "\n",
        "\tfor index in range(experiments):\n",
        "\t\tmc.start()\n",
        "\t\tfor j in range(steps):\n",
        "\t\t\tmc.move()\n",
        "\t\tif mc.running_state == 1: visits += 1\n",
        "\n",
        "\tprobability = visits / experiments\n",
        "\treturn probability\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\tmarkov_table = defineMarkovTable()\n",
        "\tinit_dist = defineInitDistribution()\n",
        "\n",
        "\tprobability = calculateProbabilities(markov_table, init_dist)\n",
        "\tprint(probability)\n",
        "\n",
        "\tPn,P0 = defineNumpyTable()\n",
        "\trealProbability = multiplyNumpyTables(Pn,P0)\n",
        "\tprint(realProbability)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.039434\n",
            "[[0.03999857 0.71997421 0.2399914 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nz6in7kFXjvA"
      },
      "source": [
        "## Απαντήσεις"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dPTu1HqYK2_"
      },
      "source": [
        "1. Το πρόγραμμα πραγματοποιεί έναν n αριθμό από πειράματα. Σε κάθε πείραμα πραγματοποιεί 40 βήματα από την αρχική θέση 1. Αν στο τέλος βρισκόμαστε στη θέση 1 τότε αυξάνουμε έναν counter. Στο τέλος διαιρούμε αυτόν τον counter με το n και έχουμε την πιθανότητα.\n",
        "2. Για τον θεωρητικό υπολογισμό της πιθανότητας δηλαδή το π(n) γνωρίζουμε ότι π(n) = π(0)*P^n , όπου π(0) οι αρχικές μας συνθήκες , δηλαδή η αρχική κατάσταση (1,0,0), n = 40 και P η στοχαστική μήτρα πιθανοτήτων μετάβασης. Το πρόγραμμα πραγματοποεί αυτούς τους υπολογισμούς και επιστρέφει το π=(π1,π2,π3) , το π1 μας ενδιαφέρει.\n",
        "3. Η θεωρητική τιμή είναι 0.03999857 και παίρνω : n=1000 π=0.041, n=10000 π=0.04, n=50000 π = 0.03952 , n=100000 π = 0.04011 , n=500000 π = 0.039434 . Παρατηρούμε ότι προσεγγίζεται αρκετά καλά αλλά ύστερα από ένα πλήθος πειραμάτων η ποιότητα σύγκλισης δεν βελτιώνεται"
      ]
    }
  ]
}