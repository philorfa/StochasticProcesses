{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stochastics_Lab9_Part1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2H70g4D1dGg"
      },
      "source": [
        "<h2><b><i>Radial Basis Function Neural Network</i></b></h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcUo-iIDz8xG"
      },
      "source": [
        "Σκοπός της παρούσας άσκησης είναι η κατηγοριοποίηση χειρόγραφων ψηφίων από το [MNIST dataset](https://www.wikiwand.com/en/MNIST_database) με τη χρήση νευρωνικών δικτύων [RBF](https://en.wikipedia.org/wiki/Radial_basis_function) (RBF). Για την κατηγοροποίηση των χειρόγραφων ψηφίων, χρησιμοποιείται ο αλγόριθμος K-means. Στη κλασική υλοποίηση του K-means όπου έχουμε το κέντρο του cluster και ταξινομομούμε κάθε σημείο με βάση την απόσταση από τα κέντρα. Σε αυτή την περίπτωση μπορεί να υπάρξουν σημεία που να μην μπορούν να αντιστοιχηθούν σε κάποιο cluster. Με τη χρήση του νευρωνικού δικτύου RBF κάθε σημείο ταξινομείται σε ομάδες με συγκεκριμένο κέντρο, γνωρίζοντας όμως τις αποστάσεις μεταξύ των κέντρων αλλά και με διαστήματα εμπιστοσύνης ως προς την πρόβλεψή μας. Με αυτό το τρόπο όλα τα σημεία αντιστοιχίζονται σε ένα cluster. Για να είναι ομαλή η ταξινόμηση των στοιχείων στα clusters μπορεί να χρησιμοποιηθεί μια εκθετική συνάρτηση υψωμένη στην αρνητική τιμή της απόστασης ως γινόμενο με έναν βαθμωτό συντελεστή beta, όπως φαίνεται παρακάτω:\n",
        "\n",
        "![alt text](https://miro.medium.com/max/145/1*MIay3aIlpT18yewOfnvTiQ.png)\n",
        "\n",
        "Στα πλαίσια του παραδείγματος για το β χρησιμοποιήθηκε ο παρακάτω τύπος\n",
        "\n",
        "![alt text](https://miro.medium.com/max/608/1*YEcI_P6orY917fQrzHQEjQ.png)\n",
        "\n",
        "Όπου k ο αριθμός των clusters και Dmax η μέγιστη ευκλείδια απόσταση μεταξύ των κέντρων. Το dataset που θα χρησιμοποιήσετε είναι διαθέσιμο [εδώ](https://drive.google.com/file/d/1WrVPB3C1vIApWNz5BaSuNmHFopf5htCg/view?usp=sharing) (θα πρέπει να το φορτώσετε στο Colab για να το τρέξετε). \n",
        "\n",
        "*Οι ερωτήσεις της άσκησης είναι μαζί με το αντίστοιχο βήμα στον κώδικα*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTqNFzQsCYiP"
      },
      "source": [
        "**Βήμα 1ο**\n",
        "\n",
        "Τρέχετε τον κώδικα στον οποίο και ορίζονται οι συναρτήσεις που θα μας χρειαστούν. Στα πλαίσια της άσκησης χρησιμοποιούμε μία παραμετροποιημένη έκδοση της συνάρτησης K-Means, όπου μας επιστρέφει τα κέντρα των ομάδων (clusters) καθώς και την τυπική απόκλιση τους."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K10m9MxE98sp"
      },
      "source": [
        "\"\"\"''\n",
        "\n",
        "Copyright © 2020 Tarlan Ahadli\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a\n",
        "copy of this software and associated documentation files (the “Software”),\n",
        "to deal in the Software without restriction, including without limitation\n",
        "the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
        "and/or sell copies of the Software, and to permit persons to whom the Software\n",
        "is furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included\n",
        "in all copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY\n",
        "KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE\n",
        "WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE\n",
        "AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\n",
        "HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\n",
        "WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
        "FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\n",
        "OTHER DEALINGS IN THE SOFTWARE.\n",
        "\n",
        "''\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_distance(x1, x2):\n",
        "    sum = 0\n",
        "    for i in range(len(x1)):\n",
        "        sum += (x1[i] - x2[i]) ** 2\n",
        "    return np.sqrt(sum)\n",
        "\n",
        "\n",
        "def kmeans(X, k, max_iters):\n",
        "    centroids = X[np.random.choice(range(len(X)), k, replace=False)]\n",
        "    # centroids = [np.random.uniform(size=len(X[0])) for i in range(k)]\n",
        "\n",
        "    converged = False\n",
        "    current_iter = 0\n",
        "\n",
        "    while (not converged) and (current_iter < max_iters):\n",
        "\n",
        "        cluster_list = [[] for i in range(len(centroids))]\n",
        "\n",
        "        for x in X:  # Go through each data point\n",
        "            distances_list = []\n",
        "            for c in centroids:\n",
        "                distances_list.append(get_distance(c, x))\n",
        "            cluster_list[int(np.argmin(distances_list))].append(x)\n",
        "\n",
        "        cluster_list = list((filter(None, cluster_list)))\n",
        "\n",
        "        prev_centroids = centroids.copy()\n",
        "\n",
        "        centroids = []\n",
        "\n",
        "        for j in range(len(cluster_list)):\n",
        "            centroids.append(np.mean(cluster_list[j], axis=0))\n",
        "\n",
        "        pattern = np.abs(np.sum(prev_centroids) - np.sum(centroids))\n",
        "\n",
        "        print('K-MEANS: ', int(pattern))\n",
        "\n",
        "        converged = (int(pattern) == 0)\n",
        "\n",
        "        current_iter += 1\n",
        "\n",
        "    return np.array(centroids), [np.std(x) for x in cluster_list]\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvN-O5euDlVg"
      },
      "source": [
        "**Βήμα 2ο**\n",
        "\n",
        "Τρέχουμε την κλάση για το RBFNN\n",
        "\n",
        "---\n",
        "\n",
        "***Ερώτηση 1***\n",
        "\n",
        "Να αναφέρετε επιγραμματικά με ποιον τρόπο λειτουργεί ένα νευρωνικό δίκτυο RBF.\n",
        "\n",
        "***Ερώτηση 2***\n",
        "\n",
        "Στα πλαίσια του παραδείγματος, για κάθε αριθμό (κλάση) έχουμε μία μόνο ομάδα (cluster). Τι θα συνέβαινε αν είχαμε παραπάνω από μία ομάδες που θα αντιστοιχούσαν σε μία κλάση; Πώς λύνεται αυτό μέσω του RBF;\n",
        "\n",
        "\n",
        "**Απάντηση 1**\n",
        "\n",
        "Ένα νευρωνικό δίκτυο RBF έχει ένα μόνο κρυφό στρώμα που αποτελείτε από νευρώνες. Οι νευρώνες αυτοί έχουν σαν χαρακτηριστικά, τα δικά τους centroids και την δικία τους συνάρτηση την λεγόμενη Radial Basis Function που εξαρτάται από τα centroids και στην περίπτωση μας είναι αυτή που αναφέρεται στην εκφώνηση. H συνάρτηση αυτή ποσοτικοποιεί την ομοιότητα ενός σημείου με το centroid και εκφράζει μια πιθανότητα να ανήκει στο cluster του συγκεκριμένου centroid. Συνεπώς αν λάβουμε αυτή τη πιθανότητα από όλους τους νευρώνες , κάθε ένας από αυτούς αντιπροσωπεύει και ενα centroid, τότε μπορούμε να αποφανθούμε και σε ποιο cluster ανήκει. Η διαδικασία που θα αποκτήσουμε τα centroids είναι συνήθως μέσω του k-means αλγόριθμου και στη συνέχεια η εκπαίδευση θα ανανεώσει τη συνεισφορά κάθε centroid-cluster σε μια συγκεκριμένη κλάση του dataset μας.  \n",
        "\n",
        "**Απάντηση 2**\n",
        "\n",
        "Οι νευρώνες του κρυφού στρώματος του RBF συνδέονται με output νευρώνες με βάρη. Στόχος των βαρών αυτών ειναι να προσδιορίσουν την συνεισφορά της ομοιότητας κάθε cluster με μία κλάση , συνεπώς αν ένα σημείο έχει πολύ μεγάλη ομοιότητα με ένα centroid-cluster υπάρχει το ενδεχόμενο να κριθεί μη σημαντική η συνεισφορά τou cluster. Έτσι θα αντιμετωπίσει το RBFNN δύο ανταγωνιστικά clusters. Ο προσδιορισμός της συνεισφοράς είναι η διαδικασία του training που έχουμε ανανέωση των βαρών.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syIsRZX-Dima"
      },
      "source": [
        "class RBF:\n",
        "\n",
        "    def __init__(self, X, y, tX, ty, num_of_classes,\n",
        "                 k, std_from_clusters=True):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "        self.tX = tX\n",
        "        self.ty = ty\n",
        "\n",
        "        self.number_of_classes = num_of_classes\n",
        "        self.k = k\n",
        "        self.std_from_clusters = std_from_clusters\n",
        "\n",
        "    def convert_to_one_hot(self, x, num_of_classes):\n",
        "        arr = np.zeros((len(x), num_of_classes))\n",
        "        for i in range(len(x)):\n",
        "            c = int(x[i])\n",
        "            arr[i][c] = 1\n",
        "        return arr\n",
        "\n",
        "    def get_rbf(self, x, c, s):\n",
        "        distance = get_distance(x, c)\n",
        "        return 1 / np.exp(-distance / s ** 2)\n",
        "\n",
        "    def get_rbf_as_list(self, X, centroids, std_list):\n",
        "        RBF_list = []\n",
        "        for x in X:\n",
        "            RBF_list.append([self.get_rbf(x, c, s) for (c, s) in zip(centroids, std_list)])\n",
        "        return np.array(RBF_list)\n",
        "\n",
        "\n",
        "    def fit(self):\n",
        "\n",
        "        self.centroids, self.std_list = kmeans(self.X, self.k, 1000)\n",
        "\n",
        "        if not self.std_from_clusters:\n",
        "            dMax = np.max([get_distance(c1, c2) for c1 in self.centroids for c2 in self.centroids])\n",
        "            self.std_list = np.repeat(dMax / np.sqrt(2 * self.k), self.k)\n",
        "\n",
        "        RBF_X = self.get_rbf_as_list(self.X, self.centroids, self.std_list)\n",
        "\n",
        "        self.w = np.linalg.pinv(RBF_X.T @ RBF_X) @ RBF_X.T @ self.convert_to_one_hot(self.y, self.number_of_classes)\n",
        "\n",
        "        RBF_list_tst = self.get_rbf_as_list(self.tX, self.centroids, self.std_list)\n",
        "\n",
        "        self.pred_ty = RBF_list_tst @ self.w\n",
        "\n",
        "        self.pred_ty = np.array([np.argmax(x) for x in self.pred_ty])\n",
        "\n",
        "        diff = self.pred_ty - self.ty\n",
        "\n",
        "        print('Accuracy: ', len(np.where(diff == 0)[0]) / len(diff))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXF5VY-UD1wo"
      },
      "source": [
        "**Βήμα 3ο**\n",
        "\n",
        "Τρέχουμε τη συνάρτηση όπου το RBFNN γίνεται fit. Αρχικά τρέχει ο αλγόριθμος k-means για να βρούμε τα κέντρα και την τυπική απόκλιση των clusters. Στη συνέχεια, μπορούμε να χρησιμοποιήσουμε το ίδιο beta για όλα τα clusters\n",
        "\n",
        "\n",
        "---\n",
        "***Ερώτηση 3***\n",
        "\n",
        "Με ποιούς τρόπους μπορούμε να υπολογίσουμε τα βάρη στα hidden layers; Ποιες διαφορές υπάρχουν στους τρόπους αυτούς; Ποιος παρέχει τη καλύτερη δυνατή λύση;\n",
        "\n",
        "**Aπάντηση 3**\n",
        "\n",
        "Μπορούμε είτε με Least Squares είτε με Gradient Desent (Batch,Stockastic κτλπ) με backpropagation. H διαφορά τους είναι ότι για την Least Squares δεν απαιτούνται πολλαπλές ενημερώσεις ούτε εποχές σε αντίθεση με τον Gradient Desent, παρόλα αυτά η μέθοδος Least Squares μπορεί να είναι πολύ απαιτητική σε μνήμη και υπολογιστική ισχύ όταν τα δεδομένα μας είναι πάρα πολλά και έχουμε και αντίστοιχα πολλά βάρη να καθορίσουμε ενώ σε μειωμένες διαστάσεις είναι αρκετά γρήγορή και οικονομική. Από τις 2 μεθόδους η Least Squares εγγυάται την βέλτιστη λύση.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWXVHJzDpZiS"
      },
      "source": [
        "**Βήμα 4ο**\n",
        "\n",
        "Σπάμε το dataset του MNIST σε training και testing και αφήνουμε το RBFNN να βγάλει το τελικό αποτέλεσμα.\n",
        "\n",
        "---\n",
        "\n",
        "***Ερώτηση 4***\n",
        "\n",
        "Επιχειρήστε να αλλάξετε την τιμή του k σε 500 και στη συνέχεια σε 1000. Τι παρατηρείτε ως προς την εκτέλεση;\n",
        "\n",
        "**Απάντηση 4**\n",
        "\n",
        "Αυξάνει πάρα πολύ ο χρόνος καθώς με k=500 προσεγγίζει την 1h30min με ενώ για k=1000 προσεγγίζει την 2h30min σε  αντίθεση με 10min οταν θέτουμε k=10, έχουμε όμως και μεγάλη αύξηση του accuracy αφού από 66% που φτάνουμε με k=10 , φτάνουμε το 95% στις δυο προηγούμενες περιπτώσεις."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1xrfJvAqEC-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c834818f-1b17-4ff0-acb3-b4898edee1d2"
      },
      "source": [
        "##################################\n",
        "\n",
        "data = np.load('/content/drive/MyDrive/Files/mnist_data.npy').astype(float)\n",
        "\n",
        "train_y = data[0:2500,0]\n",
        "train_x = data[0:2500,1:]\n",
        "\n",
        "test_y = data[2500:2800,0]\n",
        "test_x = data[2500:2800,1:]\n",
        "\n",
        "RBF_CLASSIFIER = RBF(train_x, train_y, test_x, test_y, num_of_classes=10,\n",
        "                     k=10, std_from_clusters=False)\n",
        "\n",
        "RBF_CLASSIFIER.fit()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "K-MEANS:  29688\n",
            "K-MEANS:  10256\n",
            "K-MEANS:  8099\n",
            "K-MEANS:  4374\n",
            "K-MEANS:  2685\n",
            "K-MEANS:  2096\n",
            "K-MEANS:  1118\n",
            "K-MEANS:  1268\n",
            "K-MEANS:  1090\n",
            "K-MEANS:  777\n",
            "K-MEANS:  280\n",
            "K-MEANS:  603\n",
            "K-MEANS:  339\n",
            "K-MEANS:  363\n",
            "K-MEANS:  521\n",
            "K-MEANS:  218\n",
            "K-MEANS:  56\n",
            "K-MEANS:  331\n",
            "K-MEANS:  7\n",
            "K-MEANS:  102\n",
            "K-MEANS:  31\n",
            "K-MEANS:  159\n",
            "K-MEANS:  108\n",
            "K-MEANS:  323\n",
            "K-MEANS:  59\n",
            "K-MEANS:  31\n",
            "K-MEANS:  138\n",
            "K-MEANS:  21\n",
            "K-MEANS:  2\n",
            "K-MEANS:  25\n",
            "K-MEANS:  6\n",
            "K-MEANS:  56\n",
            "K-MEANS:  56\n",
            "K-MEANS:  3\n",
            "K-MEANS:  32\n",
            "K-MEANS:  40\n",
            "K-MEANS:  47\n",
            "K-MEANS:  7\n",
            "K-MEANS:  44\n",
            "K-MEANS:  9\n",
            "K-MEANS:  0\n",
            "Accuracy:  0.6666666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nf3WCwiZ0Ylp",
        "outputId": "17abdd4c-bb23-4fd2-ff72-90634469695c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}